{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset preparation & pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.fftpack import fft\n",
    "from scipy.signal import welch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detect_peaks import detect_peaks as dpk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
       "    return false;\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.getcwd() + '\\\\data\\\\2018-09-20\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Martino\\\\Jupyter notebooks\\\\coffee_machine\\\\data\\\\2018-09-20\\\\'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA singolo file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importa un singolo file in un Dataframe di pandas\n",
    "file_name = \"2_coffee-pouring-normal-20180920--15_24_10.csv\"\n",
    "df = pd.read_csv(data_path + file_name, delimiter=',', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rinomina le feature del df\n",
    "df.rename(columns={0:'date_time', 1:'x', 2:'y', 3:'z', 4:'i'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trasforma il tipo della feature \"date_time\" nel formato date_time\n",
    "df['date_time'] = pd.to_datetime(df['date_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plottiamo le time series delle singole feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "sns.lineplot(x='date_time', y='x', data=df[0:2500], color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "sns.lineplot(x='date_time', y='y', data=df[0:2500], color='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "sns.lineplot(x='date_time', y='z', data=df[0:2500], color='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "sns.lineplot(x='date_time', y='i', data=df[0:2500], color='orange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16,6))\n",
    "\n",
    "sns.lineplot(data=df['x'][0:2500], color='r', alpha=0.3)\n",
    "sns.lineplot(data=df['y'][0:2500], color='g', alpha= 0.3)\n",
    "sns.lineplot(data=df['z'][0:2500], color='b', alpha=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA tutti i file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"importa tutti i file dei dati .csv, li etichetta\n",
    "e li concatena in un unico dataframe\"\"\"\n",
    "\n",
    "all_files = glob.glob(data_path + \"/*.csv\")\n",
    "\n",
    "dframe = pd.DataFrame()\n",
    "f_list = []\n",
    "\n",
    "for f in all_files:\n",
    "    # saltiamo i primi campioni per rimuovere il \"rumore\" iniziale\n",
    "    df = pd.read_csv(f, skiprows=1024, delimiter=',', header=None)\n",
    "    df.rename(columns={0:'date_time', 1:'x', 2:'y', 3:'z', 4:'i'}, inplace=True)\n",
    "    df['date_time'] = pd.to_datetime(df['date_time'])\n",
    "    # assegna la label a ciascun sub-dataframe\n",
    "    df['label'] = f[f.rfind('\\\\') +1]\n",
    "    f_list.append(df)\n",
    "\n",
    "# concatena i singoli df\n",
    "dframe = pd.concat(f_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dframe.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dframe.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_classes = pd.value_counts(dframe['label'], sort = True).sort_index()\n",
    "count_classes.plot(kind = 'bar')\n",
    "plt.title(\"Classes distribution\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "labels = ['empty', 'normal', 'hard', 'moving', 'stand_by', 'steam', 'normal-moving']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dframe['m'] = np.sqrt(dframe['x']**2 + dframe['y']**2 + dframe['z']**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dframe['m'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,10))\n",
    "\n",
    "for c in range(1, 8):\n",
    "    plt.plot(dframe[dframe['label'] == str(c)]['m'][0:7000], linewidth=.5, alpha=0.70)\n",
    "\n",
    "plt.legend(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-processing FFT singolo file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = '2_coffee-pouring-normal-20180920--15_24_10.csv'\n",
    "df = pd.read_csv(data_path + file_name, delimiter=',', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={0:'date_time', 1:'x', 2:'y', 3:'z', 4:'i'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date_time'] = pd.to_datetime(df['date_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLES = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[0:SAMPLES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df[500:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time_idx = len(df) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date_time'][end_time_idx] - df['date_time'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_time_sec = (df['date_time'][end_time_idx] - df['date_time'][0]).total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_time_sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = delta_time_sec/N\n",
    "T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(1/T, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_values = np.linspace(0.0, 1.0/(2.0*T), N//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_values.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_values_ = fft(df['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_values = 2.0/N * np.abs(fft_values_[0:N//2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_values.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(f_values, fft_values, linestyle='-', color='blue')\n",
    "plt.xlabel('Frequency [Hz]', fontsize=16)\n",
    "plt.ylabel('Amplitude', fontsize=16)\n",
    "plt.title(\"Frequency domain of the signal\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NB: la scala delle ascisse non corrisponde a quella reale,\n",
    "# l'indice dei picchi è invece corretto e ci consente di ottenere\n",
    "# il valore dei picchi\n",
    "ind = dpk(fft_values, mph=750, mpd=10, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funzione di Duarte editata per ottenere la giusta scala in ascissa (completare)\n",
    "#ind = detect_peaks_edit(f_values, fft_values, N, T, mph=0, mpd=20, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_values[ind]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definiamo una funzione che racchiuda gli step precedenti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"applica la FFT al segnale campionato e catturato in un file .csv\n",
    "dopo averlo importato in un DataFrame di pandas;\n",
    "chiede di specificare la variabile da processare [axis],\n",
    "il colore del plot ed eventualmente la label\"\"\"\n",
    "def preprocess_signal_FFT(file_name, axis, start_idx, end_idx, color, label=\"\"):\n",
    "    \n",
    "    # importa i dati in un DataFrame pandas\n",
    "    # data_path = os.getcwd() + '\\\\data\\\\2018-09-13\\\\'\n",
    "    data_path = os.getcwd() + '\\\\data\\\\2018-09-20\\\\'\n",
    "    df = pd.read_csv(data_path + file_name, delimiter=',', header=None)\n",
    "    df.rename(columns={0:'date_time', 1:'x', 2:'y', 3:'z', 4:'i'}, inplace=True)\n",
    "    df['date_time'] = pd.to_datetime(df['date_time'])\n",
    "    df['m'] = np.sqrt(df['x']**2 + df['y']**2 + df['z']**2)\n",
    "    df = df[start_idx:end_idx]\n",
    "    \n",
    "    # applica la FFT al segnale\n",
    "    start_time = 0\n",
    "    end_time = len(df) - 1\n",
    "    delta_time_sec = (df['date_time'][end_time] - df['date_time'][start_time]).total_seconds()\n",
    "    N = len(df)\n",
    "    T = delta_time_sec / N\n",
    "    f = 1 / T\n",
    "    f_values = np.linspace(0.0, 1.0/(2.0*T), N//2)\n",
    "    fft_values_ = fft(df[axis])\n",
    "    fft_values = 2.0/N * np.abs(fft_values_[0:N//2])\n",
    "    \n",
    "    # plotta il segnale processato\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots(figsize=(10,6))\n",
    "    ax.plot(f_values[1:], fft_values[1:], linestyle='-', color=color)\n",
    "    plt.xlabel('Frequency [Hz]', fontsize=16)\n",
    "    plt.ylabel('Amplitude', fontsize=16)\n",
    "    plt.title(\"Frequency domain of the signal \" + axis + \" \" + label, fontsize=16)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"3_coffee-pouring-hard-20180920--15_33_50.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preprocess_signal_FFT(file_name, 'x', start_idx=0, end_idx=128, color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-processing FFT tutti i file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_list = os.listdir(data_path)\n",
    "files_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {'1':'red', '2':'blue', '3':'green', '4':'orange', '5':'purple', '6':'cyan', '7':'pink'}\n",
    "labels = {'1':'(empty)', '2':'(normal pouring)', '3':'(hard pouring)', '4':'(moving)', '5':'(stand-by)', \n",
    "          '6':'(steam)', '7':'(normal-moving)'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for f in files_list:\n",
    "    file_name = f\n",
    "    c = file_name[0]\n",
    "    preprocess_signal_FFT(file_name, start_idx=0, end_idx=128, axis='x', color=colors[c], label=labels[c])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-processing PSD singolo file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = '2_coffee-pouring-normal-20180920--15_25_34.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLES = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path + file_name, delimiter=',', header=None)\n",
    "df.rename(columns={0:'date_time', 1:'x', 2:'y', 3:'z', 4:'i'}, inplace=True)\n",
    "df['date_time'] = pd.to_datetime(df['date_time'])\n",
    "df = df[0:SAMPLES]\n",
    "start_time = 0\n",
    "end_time = len(df) - 1\n",
    "delta_time_sec = (df['date_time'][end_time] - df['date_time'][start_time]).total_seconds()\n",
    "N = len(df)\n",
    "T = delta_time_sec / N\n",
    "f = 1 / T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_values, psd_values = welch(df['x'], fs=f, nperseg=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(f_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(psd_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "ax.plot(f_values, psd_values, linestyle='-', color='blue')\n",
    "plt.xlabel('Frequency [Hz]')\n",
    "plt.ylabel('PSD [V**2 / Hz]')\n",
    "plt.title(\"PSD of the signal \" + \"x\" + \" \" + \"(normal)\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definiamo una funzione che racchiuda gli step precedenti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"calcola la Power Spectral Density PSD del segnale catturato in un file .csv\n",
    "dopo averlo importato in un DataFrame di pandas;\n",
    "chiede di specificare la variabile da processare [axis], la finestra temporale\n",
    "il colore del plot ed eventualmente la label\"\"\"\n",
    "def preprocess_signal_PSD(file_name, axis, start_idx, end_idx, color, label=\"\"):\n",
    "    \n",
    "    # importa i dati in un DataFrame pandas\n",
    "    # data_path = os.getcwd() + '\\\\data\\\\2018-09-13\\\\'\n",
    "    data_path = os.getcwd() + '\\\\data\\\\2018-09-20\\\\'\n",
    "    df = pd.read_csv(data_path + file_name, delimiter=',', header=None)\n",
    "    df.rename(columns={0:'date_time', 1:'x', 2:'y', 3:'z', 4:'i'}, inplace=True)\n",
    "    df['date_time'] = pd.to_datetime(df['date_time'])\n",
    "    df['m'] = np.sqrt(df['x']**2 + df['y']**2 + df['z']**2)\n",
    "    df = df[start_idx:end_idx]\n",
    "    \n",
    "    # applica la PSD al segnale\n",
    "    start_time = 0\n",
    "    end_time = len(df) - 1\n",
    "    delta_time_sec = (df['date_time'][end_time] - df['date_time'][start_time]).total_seconds()\n",
    "    N = len(df)\n",
    "    T = delta_time_sec / N\n",
    "    f = 1 / T\n",
    "    SAMPLES = end_idx-start_idx\n",
    "    f_values, psd_values = welch(df[axis], fs=f, nperseg=SAMPLES)\n",
    "    \n",
    "    # plotta il segnale processato\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots(figsize=(10,6))\n",
    "    ax.plot(f_values, psd_values, linestyle='-', color=color)\n",
    "    plt.xlabel('Frequency [Hz]')\n",
    "    plt.ylabel('PSD [V**2 / Hz]')\n",
    "    plt.title(\"PSD of the signal \" + axis + \" \" + label, fontsize=16)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizziamo il metodo di Marcos Duarte per calcolare l'indice dei picchi nel segnale pre-processato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ./../functions/detect_peaks.py\n",
    "\"\"\"Detect peaks in data based on their amplitude and other features.\"\"\"\n",
    "\n",
    "from __future__ import division, print_function\n",
    "import numpy as np\n",
    "\n",
    "__author__ = \"Marcos Duarte, https://github.com/demotu/BMC\"\n",
    "__version__ = \"1.0.5\"\n",
    "__license__ = \"MIT\"\n",
    "\n",
    "\n",
    "def detect_peaks_edit(x_values, x, N, T, mph=None, mpd=1, threshold=0, edge='rising',\n",
    "                 kpsh=False, valley=False, show=False, ax=None):\n",
    "\n",
    "    \"\"\"Detect peaks in data based on their amplitude and other features.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : 1D array_like\n",
    "        data.\n",
    "    mph : {None, number}, optional (default = None)\n",
    "        detect peaks that are greater than minimum peak height (if parameter\n",
    "        `valley` is False) or peaks that are smaller than maximum peak height\n",
    "         (if parameter `valley` is True).\n",
    "    mpd : positive integer, optional (default = 1)\n",
    "        detect peaks that are at least separated by minimum peak distance (in\n",
    "        number of data).\n",
    "    threshold : positive number, optional (default = 0)\n",
    "        detect peaks (valleys) that are greater (smaller) than `threshold`\n",
    "        in relation to their immediate neighbors.\n",
    "    edge : {None, 'rising', 'falling', 'both'}, optional (default = 'rising')\n",
    "        for a flat peak, keep only the rising edge ('rising'), only the\n",
    "        falling edge ('falling'), both edges ('both'), or don't detect a\n",
    "        flat peak (None).\n",
    "    kpsh : bool, optional (default = False)\n",
    "        keep peaks with same height even if they are closer than `mpd`.\n",
    "    valley : bool, optional (default = False)\n",
    "        if True (1), detect valleys (local minima) instead of peaks.\n",
    "    show : bool, optional (default = False)\n",
    "        if True (1), plot data in matplotlib figure.\n",
    "    ax : a matplotlib.axes.Axes instance, optional (default = None).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ind : 1D array_like\n",
    "        indeces of the peaks in `x`.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The detection of valleys instead of peaks is performed internally by simply\n",
    "    negating the data: `ind_valleys = detect_peaks(-x)`\n",
    "    \n",
    "    The function can handle NaN's \n",
    "\n",
    "    See this IPython Notebook [1]_.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] http://nbviewer.ipython.org/github/demotu/BMC/blob/master/notebooks/DetectPeaks.ipynb\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from detect_peaks import detect_peaks\n",
    "    >>> x = np.random.randn(100)\n",
    "    >>> x[60:81] = np.nan\n",
    "    >>> # detect all peaks and plot data\n",
    "    >>> ind = detect_peaks(x, show=True)\n",
    "    >>> print(ind)\n",
    "\n",
    "    >>> x = np.sin(2*np.pi*5*np.linspace(0, 1, 200)) + np.random.randn(200)/5\n",
    "    >>> # set minimum peak height = 0 and minimum peak distance = 20\n",
    "    >>> detect_peaks(x, mph=0, mpd=20, show=True)\n",
    "\n",
    "    >>> x = [0, 1, 0, 2, 0, 3, 0, 2, 0, 1, 0]\n",
    "    >>> # set minimum peak distance = 2\n",
    "    >>> detect_peaks(x, mpd=2, show=True)\n",
    "\n",
    "    >>> x = np.sin(2*np.pi*5*np.linspace(0, 1, 200)) + np.random.randn(200)/5\n",
    "    >>> # detection of valleys instead of peaks\n",
    "    >>> detect_peaks(x, mph=-1.2, mpd=20, valley=True, show=True)\n",
    "\n",
    "    >>> x = [0, 1, 1, 0, 1, 1, 0]\n",
    "    >>> # detect both edges\n",
    "    >>> detect_peaks(x, edge='both', show=True)\n",
    "\n",
    "    >>> x = [-2, 1, -2, 2, 1, 1, 3, 0]\n",
    "    >>> # set threshold = 2\n",
    "    >>> detect_peaks(x, threshold = 2, show=True)\n",
    "\n",
    "    Version history\n",
    "    ---------------\n",
    "    '1.0.5':\n",
    "        The sign of `mph` is inverted if parameter `valley` is True\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    x = np.atleast_1d(x).astype('float64')\n",
    "    if x.size < 3:\n",
    "        return np.array([], dtype=int)\n",
    "    if valley:\n",
    "        x = -x\n",
    "        if mph is not None:\n",
    "            mph = -mph\n",
    "    # find indices of all peaks\n",
    "    dx = x[1:] - x[:-1]\n",
    "    # handle NaN's\n",
    "    indnan = np.where(np.isnan(x))[0]\n",
    "    if indnan.size:\n",
    "        x[indnan] = np.inf\n",
    "        dx[np.where(np.isnan(dx))[0]] = np.inf\n",
    "    ine, ire, ife = np.array([[], [], []], dtype=int)\n",
    "    if not edge:\n",
    "        ine = np.where((np.hstack((dx, 0)) < 0) & (np.hstack((0, dx)) > 0))[0]\n",
    "    else:\n",
    "        if edge.lower() in ['rising', 'both']:\n",
    "            ire = np.where((np.hstack((dx, 0)) <= 0) & (np.hstack((0, dx)) > 0))[0]\n",
    "        if edge.lower() in ['falling', 'both']:\n",
    "            ife = np.where((np.hstack((dx, 0)) < 0) & (np.hstack((0, dx)) >= 0))[0]\n",
    "    ind = np.unique(np.hstack((ine, ire, ife)))\n",
    "    # handle NaN's\n",
    "    if ind.size and indnan.size:\n",
    "        # NaN's and values close to NaN's cannot be peaks\n",
    "        ind = ind[np.in1d(ind, np.unique(np.hstack((indnan, indnan-1, indnan+1))), invert=True)]\n",
    "    # first and last values of x cannot be peaks\n",
    "    if ind.size and ind[0] == 0:\n",
    "        ind = ind[1:]\n",
    "    if ind.size and ind[-1] == x.size-1:\n",
    "        ind = ind[:-1]\n",
    "    # remove peaks < minimum peak height\n",
    "    if ind.size and mph is not None:\n",
    "        ind = ind[x[ind] >= mph]\n",
    "    # remove peaks - neighbors < threshold\n",
    "    if ind.size and threshold > 0:\n",
    "        dx = np.min(np.vstack([x[ind]-x[ind-1], x[ind]-x[ind+1]]), axis=0)\n",
    "        ind = np.delete(ind, np.where(dx < threshold)[0])\n",
    "    # detect small peaks closer than minimum peak distance\n",
    "    if ind.size and mpd > 1:\n",
    "        ind = ind[np.argsort(x[ind])][::-1]  # sort ind by peak height\n",
    "        idel = np.zeros(ind.size, dtype=bool)\n",
    "        for i in range(ind.size):\n",
    "            if not idel[i]:\n",
    "                # keep peaks with the same height if kpsh is True\n",
    "                idel = idel | (ind >= ind[i] - mpd) & (ind <= ind[i] + mpd) \\\n",
    "                    & (x[ind[i]] > x[ind] if kpsh else True)\n",
    "                idel[i] = 0  # Keep current peak\n",
    "        # remove the small peaks and sort back the indices by their occurrence\n",
    "        ind = np.sort(ind[~idel])\n",
    "\n",
    "    if show:\n",
    "        if indnan.size:\n",
    "            x[indnan] = np.nan\n",
    "        if valley:\n",
    "            x = -x\n",
    "            if mph is not None:\n",
    "                mph = -mph\n",
    "        _plot(x, mph, mpd, threshold, edge, valley, ax, ind)\n",
    "\n",
    "    return ind\n",
    "\n",
    "\n",
    "def _plot(x, mph, mpd, threshold, edge, valley, ax, ind):\n",
    "    \"\"\"Plot results of the detect_peaks function, see its help.\"\"\"\n",
    "    try:\n",
    "        import matplotlib.pyplot as plt\n",
    "    except ImportError:\n",
    "        print('matplotlib is not available.')\n",
    "    else:\n",
    "        if ax is None:\n",
    "            _, ax = plt.subplots(1, 1, figsize=(8, 4))\n",
    "        \n",
    "        x_values = np.linspace(0.0, 1.0/(2.0*T), N//2)\n",
    "        ax.plot(x_values, x, 'b', lw=1)\n",
    "        if ind.size:\n",
    "            label = 'valley' if valley else 'peak'\n",
    "            label = label + 's' if ind.size > 1 else label\n",
    "            ax.plot(ind, x[ind], '+', mfc=None, mec='r', mew=2, ms=8,\n",
    "                    label='%d %s' % (ind.size, label))\n",
    "            ax.legend(loc='best', framealpha=.5, numpoints=1)\n",
    "        ax.set_xlim(-.02*x.size, x.size*1.02-1)\n",
    "        ymin, ymax = x[np.isfinite(x)].min(), x[np.isfinite(x)].max()\n",
    "        yrange = ymax - ymin if ymax > ymin else 1\n",
    "        ax.set_ylim(ymin - 0.1*yrange, ymax + 0.1*yrange)\n",
    "        ax.set_xlabel('Data #', fontsize=14)\n",
    "        ax.set_ylabel('Amplitude', fontsize=14)\n",
    "        mode = 'Valley detection' if valley else 'Peak detection'\n",
    "        ax.set_title(\"%s (mph=%s, mpd=%d, threshold=%s, edge='%s')\"\n",
    "                     % (mode, str(mph), mpd, str(threshold), edge))\n",
    "        # plt.grid()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpk(psd_values, mph=100000, mpd=10, threshold=0, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_list = os.listdir(data_path)\n",
    "colors = {'1':'red', '2':'blue', '3':'green', '4':'orange', '5':'purple', '6':'cyan', '7':'pink'}\n",
    "labels = {'1':'(empty)', '2':'(normal pouring)', '3':'(hard pouring)', '4':'(moving)', '5':'(stand-by)', \n",
    "          '6':'(steam)', '7':'(normal-moving)'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in files_list:\n",
    "    file_name = f\n",
    "    c = file_name[0]\n",
    "    preprocess_signal_PSD(file_name, start_idx=0, end_idx=128, axis='x', color=colors[c], label=labels[c])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-processing autocorrelation index singolo file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = '2_coffee-pouring-normal-20180920--15_25_34.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path + file_name, delimiter=',', header=None)\n",
    "df.rename(columns={0:'date_time', 1:'x', 2:'y', 3:'z', 4:'i'}, inplace=True)\n",
    "df['date_time'] = pd.to_datetime(df['date_time'])\n",
    "df['m'] = np.sqrt(df['x']**2 + df['y']**2 + df['z']**2)\n",
    "start_time = 0\n",
    "end_time = len(df) - 1\n",
    "delta_time_sec = (df['date_time'][end_time] - df['date_time'][start_time]).total_seconds()\n",
    "N = len(df)\n",
    "T = delta_time_sec / N\n",
    "f = 1 / T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.correlate(df['x'][0:128], df['x'][0:128], mode='full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autocorr_values = result[result.size//2:]\n",
    "#autocorr_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(result[len(result)//2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_values = np.array([T * jj for jj in range(0, N+1)])\n",
    "#t_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(t_values[0:128], autocorr_values[0:128], linestyle='-', color='blue')\n",
    "plt.xlabel('time delay [s]')\n",
    "plt.ylabel('Autocorrelation amplitude')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"calcola l'indice di autocorrelazione del segnale catturato in un file .csv\n",
    "dopo averlo importato in un DataFrame di pandas;\n",
    "chiede di specificare la variabile da processare [axis], la finestra temporale,\n",
    "il colore del plot ed eventualmente la label\"\"\"\n",
    "def preprocess_signal_corr(file_name, axis, start_idx, end_idx, color, label=\"\"):\n",
    "    \n",
    "    # importa i dati in un DataFrame pandas\n",
    "    # data_path = os.getcwd() + '\\\\data\\\\2018-09-13\\\\'\n",
    "    data_path = os.getcwd() + '\\\\data\\\\2018-09-20\\\\'\n",
    "    df = pd.read_csv(data_path + file_name, delimiter=',', header=None)\n",
    "    df.rename(columns={0:'date_time', 1:'x', 2:'y', 3:'z', 4:'i'}, inplace=True)\n",
    "    df['date_time'] = pd.to_datetime(df['date_time'])\n",
    "    df['m'] = np.sqrt(df['x']**2 + df['y']**2 + df['z']**2)\n",
    "    df = df[start_idx:end_idx]\n",
    "\n",
    "    delta_time_sec = (df['date_time'][end_idx -1] - df['date_time'][start_idx]).total_seconds()\n",
    "    N = len(df)\n",
    "    T = delta_time_sec / N\n",
    "    f = 1 / T\n",
    "    \n",
    "    # calcola l'autocorrelation index\n",
    "    result = np.correlate(df['x'], df['x'], mode='full')\n",
    "    autocorr_values = result[result.size//2:]\n",
    "    t_values = np.array([T * jj for jj in range(0, N)])\n",
    "    \n",
    "    # plotta il segnale processato\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.plot(t_values[start_idx:end_idx], autocorr_values[start_idx:end_idx], linestyle='-', color=color)\n",
    "    plt.xlabel('time delay [s]')\n",
    "    plt.ylabel('Autocorrelation amplitude')\n",
    "    plt.title(\"Autocorrelation of the signal \" + axis + \" \" + label, fontsize=16)\n",
    "    plt.show()\n",
    "    plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_signal_corr(file_name, axis='x', start_idx=0, end_idx=128, color='b', label='(normal)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_list = os.listdir(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {'1':'red', '2':'blue', '3':'green', '4':'orange', '5':'purple', '6':'cyan', '7':'pink'}\n",
    "labels = {'1':'(empty)', '2':'(normal pouring)', '3':'(hard pouring)', '4':'(moving)', '5':'(stand-by)', \n",
    "          '6':'(steam)', '7':'(normal-moving)'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in files_list:\n",
    "    file_name = f\n",
    "    c = file_name[0]\n",
    "    preprocess_signal_corr(file_name, axis='x', start_idx=0, end_idx=128, color=colors[c], label=labels[c])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in files_list:\n",
    "    file_name = f\n",
    "    c = file_name[0]\n",
    "    df = pd.read_csv(data_path + f, delimiter=',', header=None)\n",
    "    print(\"Il file {0} contiene {1} sample\".format(f, len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_path = os.getcwd() + '\\\\data\\\\2018-09-20\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"importa un file .csv in un df pandas, rioganizza i nomi delle colonne\n",
    "e il formato dei dati, lo divide in due df separati secondo lo split_ratio,\n",
    "e li salva in due file .csv, uno per il training e l'altro per il testing\"\"\"\n",
    "\n",
    "def prepare_data(file_name, end_index, split_ratio):\n",
    "    \n",
    "    data_path = os.getcwd() + \"\\\\data\\\\\"\n",
    "    \n",
    "    labels = {'1':'(empty)', '2':'(normal pouring)', '3':'(hard pouring)', '4':'(moving)', '5':'(stand-by)', \n",
    "          '6':'(steam)', '7':'(normal-moving)'}\n",
    "    label = file_name[0]\n",
    "    split_index = int(end_index * split_ratio)\n",
    "    \n",
    "    df = pd.read_csv(data_path + \"2018-09-20\\\\\" + file_name, sep=',', header=None)\n",
    "    df.rename(columns={0:'date_time', 1:'x', 2:'y', 3:'z', 4:'i'}, inplace=True)\n",
    "    df['date_time'] = pd.to_datetime(df['date_time'])\n",
    "    df = df[0:end_index]\n",
    "    \n",
    "    df_train = df[0:split_index]\n",
    "    df_train.to_csv(data_path + \"INPUT_TRAIN\\\\\" + \"train_\" + labels[label] + \".csv\", sep=\",\",\n",
    "                    index=False, encoding='utf-8')\n",
    "    df_test = df[split_index:]\n",
    "    df_test.to_csv(data_path+\"INPUT_TEST\\\\\" + \"test_\" + labels[label] + \".csv\", sep=\",\",\n",
    "                   index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test con un singolo file\n",
    "file_name = \"2_coffee-pouring-normal-20180920--15_24_10.csv\"\n",
    "prepare_data(file_name, end_index=10230, split_ratio=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# per tutti i file della cartella\n",
    "for f in files_list:\n",
    "    \n",
    "    prepare_data(f, end_index=10230, split_ratio=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"importa un file .csv in un df pandas, rioganizza i nomi delle colonne\n",
    "e il formato dei dati, lo divide in due df separati secondo lo split_ratio,\n",
    "e per ogni variabile genera due file .csv, uno per il training e l'altro per il testing\"\"\"\n",
    "\n",
    "def prepare_data_split_variables(file_name, end_index, split_ratio, var_to_store):\n",
    "    \n",
    "    data_path = os.getcwd() + \"\\\\data\\\\\"\n",
    "    \n",
    "    labels = {'1':'(empty)', '2':'(normal pouring)', '3':'(hard pouring)', '4':'(moving)', '5':'(stand-by)', \n",
    "          '6':'(steam)', '7':'(normal-moving)'}\n",
    "    label = file_name[0]\n",
    "    cols={0:'date_time', 1:'x', 2:'y', 3:'z', 4:'i'}\n",
    "    split_index = int(end_index * split_ratio)\n",
    "    \n",
    "    df = pd.read_csv(data_path + \"2018-09-20\\\\\" + file_name, sep=',', header=None)\n",
    "    df.rename(columns={0:'date_time', 1:'x', 2:'y', 3:'z', 4:'i'}, inplace=True)\n",
    "    df['date_time'] = pd.to_datetime(df['date_time'])\n",
    "    df = df[0:end_index]\n",
    "    \n",
    "    df_train = df[0:split_index]\n",
    "    df_train.to_csv(data_path + \"INPUT_TRAIN\\\\\" + \"train_\" + labels[label] +\n",
    "                    \"_\" + var_to_store + \"_.csv\", sep=\",\", index=False,\n",
    "                    columns=[cols[0], var_to_store], encoding='utf-8')\n",
    "    df_test = df[split_index:]\n",
    "    df_test.to_csv(data_path+\"INPUT_TEST\\\\\" + \"test_\" + labels[label] +\n",
    "                    \"_\" + var_to_store + \"_.csv\", sep=\",\", index=False,\n",
    "                    columns=[cols[0], var_to_store], encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"2_coffee-pouring-normal-20180920--15_24_10.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test con un singolo file\n",
    "prepare_data_split_variables(file_name, end_index=10230, split_ratio=0.7, var_to_store='x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# per tutti i file della cartella\n",
    "cols={0:'date_time', 1:'x', 2:'y', 3:'z', 4:'i'}\n",
    "\n",
    "for f in files_list:\n",
    "    \n",
    "    for i in range(1,4):\n",
    "        \n",
    "        prepare_data_split_variables(f, end_index=10230, split_ratio=0.7, var_to_store=cols[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Martino\\\\Jupyter notebooks\\\\coffee_machine'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Martino\\\\Jupyter notebooks\\\\coffee_machine\\\\data\\\\2018-09-20\\\\'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_NAME = \"train_(normal pouring)_x_.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(os.getcwd() + \"\\\\data\\\\INPUT_TRAIN\\\\\" + FILE_NAME, sep=',', names='x', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-09-20 15:24:10.452</th>\n",
       "      <td>-7464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-20 15:24:10.456</th>\n",
       "      <td>3976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-20 15:24:10.458</th>\n",
       "      <td>-584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-20 15:24:10.460</th>\n",
       "      <td>-584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-20 15:24:10.462</th>\n",
       "      <td>-584</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            x\n",
       "2018-09-20 15:24:10.452 -7464\n",
       "2018-09-20 15:24:10.456  3976\n",
       "2018-09-20 15:24:10.458  -584\n",
       "2018-09-20 15:24:10.460  -584\n",
       "2018-09-20 15:24:10.462  -584"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7156</th>\n",
       "      <td>-4936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7157</th>\n",
       "      <td>-4936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7158</th>\n",
       "      <td>1212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7159</th>\n",
       "      <td>1212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7160</th>\n",
       "      <td>-144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x\n",
       "7156 -4936\n",
       "7157 -4936\n",
       "7158  1212\n",
       "7159  1212\n",
       "7160  -144"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "lngth = len(data) // 128 * 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[0:lngth]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7040"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data[0:128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 1)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data1.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1_re = np.reshape(data1.values, (1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 128)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1_re.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.array_split(data, len(data)//128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_data = np.array_split(data, len(data)//128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(split_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_signals = pd.DataFrame()\n",
    "\n",
    "for i in range(len(split_data)):\n",
    "    \n",
    "    data_reshaped = np.reshape(split_data[i].values, (1, -1))\n",
    "    \n",
    "    input_signals = input_signals.append(data_reshaped.tolist(), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(split_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_signals = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-7464</td>\n",
       "      <td>3976</td>\n",
       "      <td>-584</td>\n",
       "      <td>-584</td>\n",
       "      <td>-584</td>\n",
       "      <td>552</td>\n",
       "      <td>552</td>\n",
       "      <td>-7728</td>\n",
       "      <td>-7728</td>\n",
       "      <td>4628</td>\n",
       "      <td>...</td>\n",
       "      <td>492</td>\n",
       "      <td>492</td>\n",
       "      <td>-7572</td>\n",
       "      <td>-7572</td>\n",
       "      <td>5016</td>\n",
       "      <td>5016</td>\n",
       "      <td>-920</td>\n",
       "      <td>-920</td>\n",
       "      <td>-920</td>\n",
       "      <td>424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>424</td>\n",
       "      <td>-7448</td>\n",
       "      <td>-7448</td>\n",
       "      <td>5244</td>\n",
       "      <td>5244</td>\n",
       "      <td>-1604</td>\n",
       "      <td>-1604</td>\n",
       "      <td>-1604</td>\n",
       "      <td>-168</td>\n",
       "      <td>-168</td>\n",
       "      <td>...</td>\n",
       "      <td>4352</td>\n",
       "      <td>4352</td>\n",
       "      <td>-896</td>\n",
       "      <td>-896</td>\n",
       "      <td>868</td>\n",
       "      <td>868</td>\n",
       "      <td>-7300</td>\n",
       "      <td>-7300</td>\n",
       "      <td>-7300</td>\n",
       "      <td>4468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1316</td>\n",
       "      <td>-1316</td>\n",
       "      <td>572</td>\n",
       "      <td>572</td>\n",
       "      <td>-7288</td>\n",
       "      <td>-7288</td>\n",
       "      <td>4792</td>\n",
       "      <td>4792</td>\n",
       "      <td>-1560</td>\n",
       "      <td>-1560</td>\n",
       "      <td>...</td>\n",
       "      <td>-6668</td>\n",
       "      <td>2612</td>\n",
       "      <td>2612</td>\n",
       "      <td>2612</td>\n",
       "      <td>-264</td>\n",
       "      <td>-264</td>\n",
       "      <td>1112</td>\n",
       "      <td>1112</td>\n",
       "      <td>-7296</td>\n",
       "      <td>-7296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3480</td>\n",
       "      <td>3480</td>\n",
       "      <td>3480</td>\n",
       "      <td>-504</td>\n",
       "      <td>-504</td>\n",
       "      <td>856</td>\n",
       "      <td>856</td>\n",
       "      <td>-7220</td>\n",
       "      <td>-7220</td>\n",
       "      <td>4140</td>\n",
       "      <td>...</td>\n",
       "      <td>-40</td>\n",
       "      <td>672</td>\n",
       "      <td>672</td>\n",
       "      <td>672</td>\n",
       "      <td>-6240</td>\n",
       "      <td>-6240</td>\n",
       "      <td>2868</td>\n",
       "      <td>2868</td>\n",
       "      <td>-912</td>\n",
       "      <td>-912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1012</td>\n",
       "      <td>1012</td>\n",
       "      <td>-6492</td>\n",
       "      <td>-6492</td>\n",
       "      <td>-6492</td>\n",
       "      <td>3432</td>\n",
       "      <td>3432</td>\n",
       "      <td>-1392</td>\n",
       "      <td>-1392</td>\n",
       "      <td>948</td>\n",
       "      <td>...</td>\n",
       "      <td>1652</td>\n",
       "      <td>1652</td>\n",
       "      <td>-276</td>\n",
       "      <td>-276</td>\n",
       "      <td>556</td>\n",
       "      <td>556</td>\n",
       "      <td>-5496</td>\n",
       "      <td>-5496</td>\n",
       "      <td>2196</td>\n",
       "      <td>2196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 128 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0     1     2     3     4     5     6     7     8     9    ...    118  \\\n",
       "0 -7464  3976  -584  -584  -584   552   552 -7728 -7728  4628  ...    492   \n",
       "1   424 -7448 -7448  5244  5244 -1604 -1604 -1604  -168  -168  ...   4352   \n",
       "2 -1316 -1316   572   572 -7288 -7288  4792  4792 -1560 -1560  ...  -6668   \n",
       "3  3480  3480  3480  -504  -504   856   856 -7220 -7220  4140  ...    -40   \n",
       "4  1012  1012 -6492 -6492 -6492  3432  3432 -1392 -1392   948  ...   1652   \n",
       "\n",
       "    119   120   121   122   123   124   125   126   127  \n",
       "0   492 -7572 -7572  5016  5016  -920  -920  -920   424  \n",
       "1  4352  -896  -896   868   868 -7300 -7300 -7300  4468  \n",
       "2  2612  2612  2612  -264  -264  1112  1112 -7296 -7296  \n",
       "3   672   672   672 -6240 -6240  2868  2868  -912  -912  \n",
       "4  1652  -276  -276   556   556 -5496 -5496  2196  2196  \n",
       "\n",
       "[5 rows x 128 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_signals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>-1136</td>\n",
       "      <td>-1136</td>\n",
       "      <td>-1648</td>\n",
       "      <td>-1648</td>\n",
       "      <td>-2692</td>\n",
       "      <td>-2692</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>-852</td>\n",
       "      <td>...</td>\n",
       "      <td>2516</td>\n",
       "      <td>2516</td>\n",
       "      <td>2516</td>\n",
       "      <td>-1288</td>\n",
       "      <td>-1288</td>\n",
       "      <td>-944</td>\n",
       "      <td>-3252</td>\n",
       "      <td>-3252</td>\n",
       "      <td>2348</td>\n",
       "      <td>2348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2348</td>\n",
       "      <td>-1160</td>\n",
       "      <td>-1160</td>\n",
       "      <td>-1692</td>\n",
       "      <td>-1692</td>\n",
       "      <td>-2572</td>\n",
       "      <td>-2572</td>\n",
       "      <td>2004</td>\n",
       "      <td>2004</td>\n",
       "      <td>2004</td>\n",
       "      <td>...</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>-4288</td>\n",
       "      <td>-4288</td>\n",
       "      <td>2880</td>\n",
       "      <td>2880</td>\n",
       "      <td>-1608</td>\n",
       "      <td>-1608</td>\n",
       "      <td>-532</td>\n",
       "      <td>-532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>-3900</td>\n",
       "      <td>-3900</td>\n",
       "      <td>-3900</td>\n",
       "      <td>2624</td>\n",
       "      <td>2624</td>\n",
       "      <td>-1220</td>\n",
       "      <td>-1220</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-3228</td>\n",
       "      <td>...</td>\n",
       "      <td>3016</td>\n",
       "      <td>-1624</td>\n",
       "      <td>-1624</td>\n",
       "      <td>452</td>\n",
       "      <td>452</td>\n",
       "      <td>452</td>\n",
       "      <td>-4932</td>\n",
       "      <td>-4932</td>\n",
       "      <td>2916</td>\n",
       "      <td>2916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>-1608</td>\n",
       "      <td>-1608</td>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "      <td>-4632</td>\n",
       "      <td>-4632</td>\n",
       "      <td>-4632</td>\n",
       "      <td>2944</td>\n",
       "      <td>2944</td>\n",
       "      <td>-1696</td>\n",
       "      <td>...</td>\n",
       "      <td>684</td>\n",
       "      <td>-5332</td>\n",
       "      <td>2788</td>\n",
       "      <td>2788</td>\n",
       "      <td>-1400</td>\n",
       "      <td>-1400</td>\n",
       "      <td>588</td>\n",
       "      <td>588</td>\n",
       "      <td>588</td>\n",
       "      <td>-4976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>-4976</td>\n",
       "      <td>2872</td>\n",
       "      <td>2872</td>\n",
       "      <td>-1616</td>\n",
       "      <td>-1616</td>\n",
       "      <td>356</td>\n",
       "      <td>356</td>\n",
       "      <td>356</td>\n",
       "      <td>-4844</td>\n",
       "      <td>-4844</td>\n",
       "      <td>...</td>\n",
       "      <td>692</td>\n",
       "      <td>692</td>\n",
       "      <td>-5332</td>\n",
       "      <td>-5332</td>\n",
       "      <td>-5332</td>\n",
       "      <td>2660</td>\n",
       "      <td>2660</td>\n",
       "      <td>-1304</td>\n",
       "      <td>-1304</td>\n",
       "      <td>632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 128 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1     2     3     4     5     6     7     8     9    ...    118  \\\n",
       "50 -1136 -1136 -1648 -1648 -2692 -2692  2000  2000  2000  -852  ...   2516   \n",
       "51  2348 -1160 -1160 -1692 -1692 -2572 -2572  2004  2004  2004  ...     72   \n",
       "52 -3900 -3900 -3900  2624  2624 -1220 -1220 -1000 -1000 -3228  ...   3016   \n",
       "53 -1608 -1608    84    84 -4632 -4632 -4632  2944  2944 -1696  ...    684   \n",
       "54 -4976  2872  2872 -1616 -1616   356   356   356 -4844 -4844  ...    692   \n",
       "\n",
       "     119   120   121   122   123   124   125   126   127  \n",
       "50  2516  2516 -1288 -1288  -944 -3252 -3252  2348  2348  \n",
       "51    72 -4288 -4288  2880  2880 -1608 -1608  -532  -532  \n",
       "52 -1624 -1624   452   452   452 -4932 -4932  2916  2916  \n",
       "53 -5332  2788  2788 -1400 -1400   588   588   588 -4976  \n",
       "54   692 -5332 -5332 -5332  2660  2660 -1304 -1304   632  \n",
       "\n",
       "[5 rows x 128 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_signals.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
